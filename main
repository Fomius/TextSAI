import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
import speech_recognition as sr
from langdetect import detect
from transformers import BertTokenizer, TFBertForSequenceClassification
import tensorflow as tf
import nltk
from rake_nltk import Rake
import spacy
import sys
from PySide6.QtWidgets import QApplication, QMainWindow, QApplication, QFrame, QLabel, QTextEdit
from ui_main import Ui_Maim_window
import webbrowser

# Загрузка предобученной модели BERT и токенизатора
model = TFBertForSequenceClassification.from_pretrained(«bert–base–uncased»)
tokenizer = BertTokenizer.from_pretrained(«bert–base–uncased»)
class MainWindow(QMainWindow):
    def __init__(self):
        super(MainWindow, self).__init__()
        self.ui = Ui_Maim_window()
        self.ui.setupUi(self)

        # Привязываем функции к кнопкам
        self.ui.analyze_tn_button.clicked.connect(self.analyze_tn)
        self.ui.analyze_selection_button.clicked.connect(self.analyze_selection)
        self.ui.voice_input_button.clicked.connect(self.voice_input)
        self.ui.vk_Button.clicked.connect(self.open_vk_link)
        self.ui.tg_Button.clicked.connect(self.open_tg_link)

    def voice_input(self):
        recognizer = sr.Recognizer()
        with sr.Microphone() as source:
            self.ui.result_text.setPlainText(«Говорите сейчас...»)
            recognizer.adjust_for_ambient_noise(source)
            audio = recognizer.listen(source)
        try:
            text = recognizer.recognize_google(audio, language=«ru–RU»)
            self.ui.text_entry.clear()
            self.ui.text_entry.insertPlainText(text)
        except sr.UnknownValueError:
            self.ui.result_text.setPlainText(«Извините, не удалось распознать речь.»)
        except sr.RequestError as e:
            self.ui.result_text.setPlainText(«Ошибка сервиса распознавания речи; {0}».format(e))

    def analyze_tn(self):
        # Получаем текст из поля ввода
        text = self.ui.text_entry.toPlainText()

        # Токенизация предложения
        tokens = nltk.word_tokenize(text)
        # Определение частей речи для каждого токена
        tagged = nltk.pos_tag(tokens)
        # Классификация результатов
        classified_tagged = [(word, tag, 'существительное' if tag.startswith('NN') else  # 'NN' – существительное
        'прилагательное' if tag.startswith('JJ') else  # 'JJ' – прилагательное
        'глагол' if tag.startswith('VB') else  # 'VB' – глагол
        'предлог' if tag.startswith('IN') else  # 'IN' – предлог
        'артикль' if tag.startswith('DT') else  # 'DT' – артикль
        'наречие' if tag.startswith('RB') else  # 'RB' – наречие
        'союз' if tag.startswith('CC') else  # 'CC' – союз
        'местоимение' if tag.startswith('PRP') else 'не знакомо')  # 'PRP' – местоимение
                             for word, tag in tagged]

        counts = {'существительное': 0, 'прилагательное': 0, 'глагол': 0, 'предлог': 0, 'артикль': 0, 'наречие': 0,
                  'союз': 0, 'местоимение': 0, 'не знакомо': 0}
        for _, _, classification in classified_tagged:
            counts[classification] += 1
        # Формируем текст результата
        result_text = ««
        for classification, count in counts.items():
            result_text += f»{classification}: {count}\n»

        # Выводим результаты в текстовое поле результата
        self.ui.result_text.setPlainText(result_text)

        # Дополнительный анализ текста
        # Считаем количество слов в тексте
        word_count = len(text.split())
        # Определяем язык текста
        language = detect(text)
        # Проводим токенизацию текста
        inputs = tokenizer(text, return_tensors=«tf», padding=True, truncation=True, max_length=128)
        # Получаем предсказание модели
        outputs = model(inputs)

        predictions = tf.nn.softmax(outputs.logits, axis=–1)
        predicted_class = tf.argmax(predictions, axis=1).numpy()[0]

        # Выводим дополнительные результаты в текстовое поле результата
        if predicted_class == 0:
            sentiment = «Негативный»
        else:
            sentiment = «Позитивный»
        result_text += f»\nЯзык текста: {language}\n{sentiment}\nКоличество слов в тексте: {word_count}\n»

        # Выводим обновленные результаты в текстовое поле результата
        self.ui.result_text.setPlainText(result_text)

    def analyze_selection(self):
        # Получаем текст из поля ввода
        text = self.ui.text_entry.toPlainText()
        # Загрузка модели языка для русского
        nlp = spacy.load(«ru_core_news_sm»)
        # Функция для извлечения информации из текста
        def extract_information(textxtract):
            doc = nlp(textxtract)
            # Извлечение именованных сущностей
            entities = [(ent.text, ent.label_) for ent in doc.ents]
            # Извлечение глаголов
            verbs = [token.lemma_ for token in doc if token.pos_ == «VERB»]
            # Инициализация Rake для извлечения ключевых фраз
            rake = Rake(language=«russian»)
            rake.extract_keywords_from_text(textxtract)
            key_phrases = rake.get_ranked_phrases()

            return entities, verbs, key_phrases

        # Извлекаем информацию из текста
        entities, verbs, key_phrases = extract_information(text)
        # Формируем текст результата
        result_text = f»Именованные сущности:\n{entities}\n»
        result_text += f»\nГлаголы:\n{verbs}\n»
        result_text += f»\nКлючевые фразы:\n{key_phrases}»
        # Выводим результаты в текстовое поле результата
        self.ui.result_text.setPlainText(result_text)
    def open_vk_link(self):
        import webbrowser
        webbrowser.open('https://vk.com/fomiys')
    def open_tg_link(self):
        import webbrowser
        webbrowser.open('https://t.me/Fomiys_the_Animys')

if __name__ == «__main__»:
    app = QApplication(sys.argv)
    window = MainWindow()
    window.show()
    sys.exit(app.exec())
